# 数据库和缓存一致性：缓存更新的套路
&nbsp;&nbsp;更新缓存的Design Pattern 有四种: Cache aside、Read Through、Write Behind Caching

## Cache Aside Pattern
&nbsp;&nbsp;最常用的模式，具体逻辑如下:
- 失效： 应用程序先从cache中取数据，没有得到，则从数据库中取数据，成功后，刷新到缓存中。
- 命中： 应用程序从cache中取数据，取到后返回。
- 更新： 先把数据存到数据库中，成功后，再让缓存失效<sup>注意，这里是让缓存失效，而不是更新缓存：防止两个并发的写操作导致脏数据</sup>。
  > <img src="./pics/Cache-Aside-Design-Pattern-Flow-Diagram-e1470471723210.png"/>
    - 第3点： 即 从数据库中获取到数据后，在返回的时候，将数据刷新到缓存中
  > <img src="./pics/Updating-Data-using-the-Cache-Aside-Pattern-Flow-Diagram-1-e1470471761402.png"/>

### 存在的问题
&nbsp;&nbsp;如，一个读操作，但是没有命中缓存，然后去数据库中读取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的读操作再把老的数据放进去，所以，会造成脏数据。
> 解决方案: 这种情况理论上会出现，但是出现的概率很低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上，数据库的写操作会比读操作慢的多，而且要锁表，而读操作必须在写操作之前进入数据库操作，而又要晚于写操作更新缓存，所以这些条件都具备的概率基本不大。

## Read Through
&nbsp;&nbsp;Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。

## Write Through
&nbsp;&nbsp;Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

## Write Behind Caching Pattern
&nbsp;&nbsp;Write Behind 又叫 Write Back<sup>Linux文件系统的Page Cache的算法</sup>。Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write back还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。

&nbsp;&nbsp;但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性能是有冲突的。软件设计从来都是取舍Trade-Off。

&nbsp;&nbsp;另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。